{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "067f6fd4-9824-45b2-856a-f7dd3275e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports - these are all the imports needed for the assignment\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import nltk package \n",
    "#   PennTreeBank word tokenizer \n",
    "#   English language stopwords\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# scikit-learn imports\n",
    "#   SVM (Support Vector Machine) classifer \n",
    "#   Vectorizer, which transforms text data into bag-of-words feature\n",
    "#   TF-IDF Vectorizer that first removes widely used words in the dataset and then transforms test data\n",
    "#   Metrics functions to evaluate performance\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa993ee1-6eb7-42d3-b80b-91557423f351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor this assignment we will be using nltk: the Natural Language Toolkit.\\n\\nTo do so, we will need to download some text data.\\n\\nNatural language processing (NLP) often requires corpus data (lists of words, and/or example text data) \\nwhich is what we will download here now, if you don’t already have them.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "For this assignment we will be using nltk: the Natural Language Toolkit.\n",
    "\n",
    "To do so, we will need to download some text data.\n",
    "\n",
    "Natural language processing (NLP) often requires corpus data (lists of words, and/or example text data) \n",
    "which is what we will download here now, if you don’t already have them.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0bf1c7a-ee46-469d-813b-56b09ffc2920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/solavancininoceti/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/solavancininoceti/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the NLTK English tokenizer and the stopwords of all languages\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2053e46-8264-41c7-bf09-3a35c7a3cfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDownloading Data\\n\\nIf you download this notebook to run locally, you will also need some data files.\\n\\nRunning the next cell will download the required files for this assignment.\\n\\nYou can also view and download these files from https://github.com/DataScienceInPractice/Data.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Downloading Data\n",
    "\n",
    "If you download this notebook to run locally, you will also need some data files.\n",
    "\n",
    "Running the next cell will download the required files for this assignment.\n",
    "\n",
    "You can also view and download these files from https://github.com/DataScienceInPractice/Data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a181903-0265-4cb3-b6d2-120451a1c1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPart 1: Sentiment Analysis on Movie Review Data (4.25 points)\\nIn part 1 we will apply sentiment analysis to Movie Review (MR) data.\\n\\nThe MR data contains more than 10,000 reviews collected from the IMDB website, \\nand each of the reviews is annotated as either positive or negative. \\nThe number of positive and negative reviews are roughly the same. \\nFor more information about the dataset, you can visit http://www.cs.cornell.edu/people/pabo/movie-review-data/\\nFor this homework assignment, we’ve already shuffled the data, and truncated the data to contain only 5000 reviews.\\nIn this part of the assignment we will:\\n\\nTransform the raw text data into vectors with the BoW encoding method\\nSplit the data into training and test sets\\nWrite a function to train an SVM classifier on the training set\\nTest this classifier on the test set and report the results\\n1a) Import data\\n\\nImport the textfile ‘rt-polarity.tsv’ into a DataFrame called MR_df,\\n\\nSet the column names as ‘index’, ‘label’, ‘review’\\n\\nNote that ‘rt-polarity.tsv’ is a tab separated raw text file, in which data is separated by tabs (‘\\t’). \\nYou can load this file with read_csv, specifying the sep (separator) argument as tabs (‘\\t’). \\nYou will have to set header as None.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Part 1: Sentiment Analysis on Movie Review Data (4.25 points)\n",
    "In part 1 we will apply sentiment analysis to Movie Review (MR) data.\n",
    "\n",
    "The MR data contains more than 10,000 reviews collected from the IMDB website, \n",
    "and each of the reviews is annotated as either positive or negative. \n",
    "The number of positive and negative reviews are roughly the same. \n",
    "For more information about the dataset, you can visit http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "For this homework assignment, we’ve already shuffled the data, and truncated the data to contain only 5000 reviews.\n",
    "In this part of the assignment we will:\n",
    "\n",
    "Transform the raw text data into vectors with the BoW encoding method\n",
    "Split the data into training and test sets\n",
    "Write a function to train an SVM classifier on the training set\n",
    "Test this classifier on the test set and report the results\n",
    "1a) Import data\n",
    "\n",
    "Import the textfile ‘rt-polarity.tsv’ into a DataFrame called MR_df,\n",
    "\n",
    "Set the column names as ‘index’, ‘label’, ‘review’\n",
    "\n",
    "Note that ‘rt-polarity.tsv’ is a tab separated raw text file, in which data is separated by tabs (‘\\t’). \n",
    "You can load this file with read_csv, specifying the sep (separator) argument as tabs (‘\\t’). \n",
    "You will have to set header as None.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71efeb25-74bf-4996-afc0-409c5eb8e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MR_df = pd.read_csv('rt-polarity.tsv', sep='\\t', header=None, names=['index', 'label', 'review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7518e6b3-7c44-479b-abec-74d1bf9ba61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(MR_df, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c71625f7-5e11-45b5-95a4-6f3a643bef2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8477</td>\n",
       "      <td>neg</td>\n",
       "      <td>except as an acting exercise or an exceptional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4031</td>\n",
       "      <td>pos</td>\n",
       "      <td>japanese director shohei imamura 's latest fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10240</td>\n",
       "      <td>neg</td>\n",
       "      <td>i walked away not really know who `` they `` w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8252</td>\n",
       "      <td>neg</td>\n",
       "      <td>what could have been a neat little story about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1346</td>\n",
       "      <td>pos</td>\n",
       "      <td>no screen fantasy-adventure in recent memory h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index label                                             review\n",
       "0   8477   neg  except as an acting exercise or an exceptional...\n",
       "1   4031   pos  japanese director shohei imamura 's latest fil...\n",
       "2  10240   neg  i walked away not really know who `` they `` w...\n",
       "3   8252   neg  what could have been a neat little story about...\n",
       "4   1346   pos  no screen fantasy-adventure in recent memory h..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data\n",
    "MR_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70259055-ef4c-48c5-bd2d-50772e1de8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1b) Create a function that converts string labels to numerical labels\\n\\nFunction name: convert_label\\n\\nThe function should do the following:\\n\\nif the input label is “pos” return 1.0\\nif the input label is “neg” return 0.0\\notherwise, return the input label as is\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1b) Create a function that converts string labels to numerical labels\n",
    "\n",
    "Function name: convert_label\n",
    "\n",
    "The function should do the following:\n",
    "\n",
    "if the input label is “pos” return 1.0\n",
    "if the input label is “neg” return 0.0\n",
    "otherwise, return the input label as is\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5802d3f-8c83-4c4d-9bbc-db89afd23e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(label):\n",
    "    if label == 'pos':\n",
    "        return 1.0\n",
    "    elif label == 'neg':\n",
    "        return 0.0\n",
    "    else:\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d938b102-09d3-4d48-be07-cb60b034a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert callable(convert_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bc4da13-57ea-4bfe-b399-be2e4dddf9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1c) Numerical Labels\\n\\nConvert all labels in MR_df[\"label\"] to numerical labels, using the convert_label function.\\n\\nSave them as a new column named “y” in MR_df.\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1c) Numerical Labels\n",
    "\n",
    "Convert all labels in MR_df[\"label\"] to numerical labels, using the convert_label function.\n",
    "\n",
    "Save them as a new column named “y” in MR_df.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dcd94f4e-3f26-4af3-b3e6-2eb0b536516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MR_df['y'] = MR_df['label'].apply(convert_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a208d82-3f9d-43dd-8a24-351dfe4bccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sorted(set(MR_df['y'])) == [0., 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6f0fd5b-67ca-4d63-8435-e681ecb8ed08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8477</td>\n",
       "      <td>neg</td>\n",
       "      <td>except as an acting exercise or an exceptional...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4031</td>\n",
       "      <td>pos</td>\n",
       "      <td>japanese director shohei imamura 's latest fil...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10240</td>\n",
       "      <td>neg</td>\n",
       "      <td>i walked away not really know who `` they `` w...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8252</td>\n",
       "      <td>neg</td>\n",
       "      <td>what could have been a neat little story about...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1346</td>\n",
       "      <td>pos</td>\n",
       "      <td>no screen fantasy-adventure in recent memory h...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index label                                             review    y\n",
       "0   8477   neg  except as an acting exercise or an exceptional...  0.0\n",
       "1   4031   pos  japanese director shohei imamura 's latest fil...  1.0\n",
       "2  10240   neg  i walked away not really know who `` they `` w...  0.0\n",
       "3   8252   neg  what could have been a neat little story about...  0.0\n",
       "4   1346   pos  no screen fantasy-adventure in recent memory h...  1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the MR_df data\n",
    "MR_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6ccd03c-9e82-4f94-a8a6-ba23757ce8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n1d) Convert Text data into vector\\n\\nWe will now create a CountVectorizer object to transform the text data into vectors with numerical values.\\n\\nTo do so, we will initialize a CountVectorizer object, and name it as vectorizer.\\n\\nWe need to pass 4 arguments to initialize a CountVectorizer:\\n\\nanalyzer: 'word' Specify to analyze data from word-level.\\nmax_features: 2000 Set a max number of unique words.\\ntokenizer: word_tokenize Set to tokenize the text data by using the word_tokenizer from NLTK .\\nstop_words: stopwords.words('english') Set to remove all stopwords in English. \\nWe do this since they generally don’t provide useful discriminative information.\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1d) Convert Text data into vector\n",
    "\n",
    "We will now create a CountVectorizer object to transform the text data into vectors with numerical values.\n",
    "\n",
    "To do so, we will initialize a CountVectorizer object, and name it as vectorizer.\n",
    "\n",
    "We need to pass 4 arguments to initialize a CountVectorizer:\n",
    "\n",
    "analyzer: 'word' Specify to analyze data from word-level.\n",
    "max_features: 2000 Set a max number of unique words.\n",
    "tokenizer: word_tokenize Set to tokenize the text data by using the word_tokenizer from NLTK .\n",
    "stop_words: stopwords.words('english') Set to remove all stopwords in English. \n",
    "We do this since they generally don’t provide useful discriminative information.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1613c7a0-c97a-4680-97fe-73a3d8d91262",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', max_features=2000, tokenizer=word_tokenize, stop_words=stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0aeb2a9c-7a64-488b-a8df-519bbc25ff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert vectorizer.analyzer == 'word'\n",
    "assert vectorizer.max_features == 2000\n",
    "assert vectorizer.tokenizer == word_tokenize\n",
    "assert vectorizer.stop_words == stopwords.words('english')\n",
    "assert hasattr(vectorizer, \"fit_transform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c4b20a4-9069-482a-84c5-f2d8afbf8df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1e) Vectorize reviews\\n\\nTransform reviews MR_df[\"review\"] into vectors using the vectorizer we created above:\\n\\nThe method you will be using is: MR_X = vectorizer.fit_transform(...).toarray()\\n\\nNote that we apply the toarray method to the type cast the output to a numpy array. \\nThis is something we will do multiple times, turning custom sklearn objects back into arrays.\\n\\nNote this may post a warning about stopwords. This is ok.\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1e) Vectorize reviews\n",
    "\n",
    "Transform reviews MR_df[\"review\"] into vectors using the vectorizer we created above:\n",
    "\n",
    "The method you will be using is: MR_X = vectorizer.fit_transform(...).toarray()\n",
    "\n",
    "Note that we apply the toarray method to the type cast the output to a numpy array. \n",
    "This is something we will do multiple times, turning custom sklearn objects back into arrays.\n",
    "\n",
    "Note this may post a warning about stopwords. This is ok.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "de0ab6eb-7a07-4bef-bc68-ed02eac54864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2000)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MR_X = vectorizer.fit_transform(MR_df['review']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad410afc-71e2-4769-9416-1abe58be0429",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(MR_X) == np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "002436cc-2276-4bcc-b2c8-c62677c7c5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1f) Outcome variable\\n\\nCopy out the y column in MR_df and save it as an np.array named MR_y\\n\\nMake sure the shape of MR_y is (5000,) - depending upon your earlier approach, you may have to use reshape to do so.\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1f) Outcome variable\n",
    "\n",
    "Copy out the y column in MR_df and save it as an np.array named MR_y\n",
    "\n",
    "Make sure the shape of MR_y is (5000,) - depending upon your earlier approach, you may have to use reshape to do so.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "556403cb-2bfc-42bd-bfcb-dffa759ab332",
   "metadata": {},
   "outputs": [],
   "source": [
    "MR_y = np.array(MR_df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4880e032-adf2-44fa-813d-6f7420fb19cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MR_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "49692e1d-ab0a-401b-913c-e7e8c2741648",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert MR_y.shape == (5000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2fa7c076-bd1f-4779-9a1d-9d4e832d5d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1g) Defining the train & test sets\\n\\nWe first set 80% of the data as the training set to train an SVM classifier. \\nWe will then test the learnt classifier on the remaining 20% of data samples (test set). \\n(Reminder: For this homework assignment, we’ve already shuffled the data)\\n\\nCalculate the number of training data samples (80% of total) and store it in num_training\\nCalculate the number of test data samples (20% of total) and store it in num_testing\\nMake sure both of these variables are of type int\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1g) Defining the train & test sets\n",
    "\n",
    "We first set 80% of the data as the training set to train an SVM classifier. \n",
    "We will then test the learnt classifier on the remaining 20% of data samples (test set). \n",
    "(Reminder: For this homework assignment, we’ve already shuffled the data)\n",
    "\n",
    "Calculate the number of training data samples (80% of total) and store it in num_training\n",
    "Calculate the number of test data samples (20% of total) and store it in num_testing\n",
    "Make sure both of these variables are of type int\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0b3f1ba-fe45-46bd-9d72-25c0a534442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training = int(len(MR_y) * 0.8)\n",
    "num_testing = int(len(MR_y) * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f93c8f0-600b-4b5d-96f4-f5f14525b586",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(num_training) == int\n",
    "assert type(num_testing) == int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3855d0f7-4cb1-47b9-8b63-6c2f4823c0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1h) Extracting train & test Data\\n\\nSplit the MR_X and MR_y into training set and test set. \\nYou should use the num_training variable to extract the data from MR_X and MR_y.\\n\\nExtract the first num_training samples as training data, and extract the rest as test data.\\n\\nName them as:\\n\\nMR_train_X and MR_train_y for the training set\\nMR_test_X and MR_test_y for the test set\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1h) Extracting train & test Data\n",
    "\n",
    "Split the MR_X and MR_y into training set and test set. \n",
    "You should use the num_training variable to extract the data from MR_X and MR_y.\n",
    "\n",
    "Extract the first num_training samples as training data, and extract the rest as test data.\n",
    "\n",
    "Name them as:\n",
    "\n",
    "MR_train_X and MR_train_y for the training set\n",
    "MR_test_X and MR_test_y for the test set\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8532ce06-442a-4d34-ab43-d4e94d9b8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MR_train_X = MR_X[:num_training]\n",
    "MR_train_y = MR_y[:num_training]\n",
    "MR_test_X = MR_X[num_training:]\n",
    "MR_test_y = MR_y[num_training:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cdd4876a-7cd3-4dad-93c9-a49189c7eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert MR_train_X.shape[0] == MR_train_y.shape[0]\n",
    "assert MR_test_X.shape[0] == MR_test_y.shape[0]\n",
    "\n",
    "assert len(MR_train_X) == 4000\n",
    "assert len(MR_test_y) == 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0740a989-5a22-4f68-abc5-e199523f5520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1i) SVM\\n\\nDefine a function called train_SVM that initializes an SVM classifier and trains it\\n\\nInputs:\\n\\nX: np.ndarray, training samples,\\ny: np.ndarray, training labels,\\nkernel: string, set the default value of “kernel” as “linear”\\nOutput: a trained classifier clf\\n\\nHint: There are 2 steps involved in this function:\\n\\nInitializing an SVM classifier: clf = SVC(...)\\nTraining the classifier: clf.fit(X, y)\\n'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1i) SVM\n",
    "\n",
    "Define a function called train_SVM that initializes an SVM classifier and trains it\n",
    "\n",
    "Inputs:\n",
    "\n",
    "X: np.ndarray, training samples,\n",
    "y: np.ndarray, training labels,\n",
    "kernel: string, set the default value of “kernel” as “linear”\n",
    "Output: a trained classifier clf\n",
    "\n",
    "Hint: There are 2 steps involved in this function:\n",
    "\n",
    "Initializing an SVM classifier: clf = SVC(...)\n",
    "Training the classifier: clf.fit(X, y)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "30f31d6f-f7d4-474c-a582-686e4dd8a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SVM(X, y):\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "eb4c5132-c195-4bc7-b1ff-3af6dc52e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert callable(train_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4f54bcc3-0b8b-4f86-8a0f-5c076234073a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1j) Train SVM\\n\\nTrain an SVM classifier with the default linear kernel on the samples MR_train_X and the labels MR_train_y\\n\\nYou need to call the function train_SVM you just created. Name the returned object as MR_clf.\\n\\nNote that running this function may take many seconds / up to a few minutes to run.\\n'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1j) Train SVM\n",
    "\n",
    "Train an SVM classifier with the default linear kernel on the samples MR_train_X and the labels MR_train_y\n",
    "\n",
    "You need to call the function train_SVM you just created. Name the returned object as MR_clf.\n",
    "\n",
    "Note that running this function may take many seconds / up to a few minutes to run.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "58c2438a-4197-47d8-aa39-fed354ec7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "MR_clf = train_SVM(MR_train_X, MR_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1bf14da3-659b-4f19-9060-17f130caae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(MR_clf, SVC)\n",
    "assert hasattr(MR_clf, \"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "44bab666-6c79-44a3-b999-ad892afbeab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1k) Predict outcome\\n\\nPredict labels for both training samples and test samples. You will need to use MR_clf.predict(...)\\n\\nName the predicted labels for the training samples as MR_predicted_train_y. \\nName the predicted labels for the testing samples as MR_predicted_test_y.\\n\\nYour code here will also take a minute to run.\\n\\n'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1k) Predict outcome\n",
    "\n",
    "Predict labels for both training samples and test samples. You will need to use MR_clf.predict(...)\n",
    "\n",
    "Name the predicted labels for the training samples as MR_predicted_train_y. \n",
    "Name the predicted labels for the testing samples as MR_predicted_test_y.\n",
    "\n",
    "Your code here will also take a minute to run.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9806c98c-3e74-455d-a435-6b6c7a060335",
   "metadata": {},
   "outputs": [],
   "source": [
    "MR_predicted_train_y = MR_clf.predict(MR_train_X)\n",
    "MR_predicted_test_y = MR_clf.predict(MR_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "028ea9a5-c126-477a-9eaa-e3a212c34945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.91      0.91      2008\n",
      "         1.0       0.91      0.91      0.91      1992\n",
      "\n",
      "    accuracy                           0.91      4000\n",
      "   macro avg       0.91      0.91      0.91      4000\n",
      "weighted avg       0.91      0.91      0.91      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Now we will use the function classification_report to print out the performance of the classifier on the training set:\n",
    "\n",
    "'''\n",
    "# Your classifier should be able to reach above 90% accuracy \n",
    "# on the training set\n",
    "print(classification_report(MR_train_y,MR_predicted_train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fb51da64-141b-476d-b047-05239304828a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.68      0.68       482\n",
      "         1.0       0.70      0.70      0.70       518\n",
      "\n",
      "    accuracy                           0.69      1000\n",
      "   macro avg       0.69      0.69      0.69      1000\n",
      "weighted avg       0.69      0.69      0.69      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "And finally, we check the performance of the trained classifier on the test set:\n",
    "'''\n",
    "# Your classifier should be able to reach around 70% accuracy on the test set.\n",
    "print(classification_report(MR_test_y, MR_predicted_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3b8b1913-1fee-4dc3-99e0-c66b77d2fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert MR_predicted_train_y.shape == (4000,)\n",
    "assert MR_predicted_test_y.shape == (1000,)\n",
    "\n",
    "precision, recall, _, _ = precision_recall_fscore_support(MR_train_y,MR_predicted_train_y)\n",
    "assert np.isclose(precision[0], 0.91, 0.02)\n",
    "assert np.isclose(precision[1], 0.92, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ad142a7d-2fe6-4aa1-9a2f-4f25cb74344b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPart 2: TF-IDF (1.25 points)\\nIn this part, we will explore TF-IDF on sentiment analysis.\\n\\nTF-IDF is used as an alternate way to encode text data, as compared to the BoW approach used in Part 1.\\n\\nTo do this, we will:\\n\\nTransform the raw text data into vectors using TF-IDF\\nTrain an SVM classifier on the training set and report the performance this classifer on the test set\\n2a) Text Data to Vectors\\n\\nWe will create a TfidfVectorizer object to transform the text data into vectors with TF-IDF\\n\\nTo do so, we will initialize a TfidfVectorizer object, and name it as tfidf.\\n\\nWe need to pass 4 arguments into the “TfidfVectorizer” to initialize a “tfidf”:\\n\\nsublinear_tf: True Set to apply TF scaling.\\nanalyzer: 'word' Set to analyze the data at the word-level\\nmax_features: 2000 Set the max number of unique words\\ntokenizer: word_tokenize Set to tokenize the text data by using the word_tokenizer from NLTK\\n\""
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Part 2: TF-IDF (1.25 points)\n",
    "In this part, we will explore TF-IDF on sentiment analysis.\n",
    "\n",
    "TF-IDF is used as an alternate way to encode text data, as compared to the BoW approach used in Part 1.\n",
    "\n",
    "To do this, we will:\n",
    "\n",
    "Transform the raw text data into vectors using TF-IDF\n",
    "Train an SVM classifier on the training set and report the performance this classifer on the test set\n",
    "2a) Text Data to Vectors\n",
    "\n",
    "We will create a TfidfVectorizer object to transform the text data into vectors with TF-IDF\n",
    "\n",
    "To do so, we will initialize a TfidfVectorizer object, and name it as tfidf.\n",
    "\n",
    "We need to pass 4 arguments into the “TfidfVectorizer” to initialize a “tfidf”:\n",
    "\n",
    "sublinear_tf: True Set to apply TF scaling.\n",
    "analyzer: 'word' Set to analyze the data at the word-level\n",
    "max_features: 2000 Set the max number of unique words\n",
    "tokenizer: word_tokenize Set to tokenize the text data by using the word_tokenizer from NLTK\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "22f65b77-9ac5-46cb-901b-d6cd29a9e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, analyzer='word', max_features=2000, tokenizer=word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b58dfc5e-e8bc-481a-8eab-1241e7535836",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tfidf.analyzer == 'word'\n",
    "assert tfidf.max_features == 2000\n",
    "assert tfidf.tokenizer == word_tokenize\n",
    "assert tfidf.stop_words == None\n",
    "assert hasattr(vectorizer, \"fit_transform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7342128b-c84a-4d2b-8a7c-52a63216ced5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n2b) Transform Reviews\\n\\nTransform the review column of MR_df into vectors using the tfidf we created above.\\n\\nSave the transformed data into a variable called MR_tfidf_X\\n\\nHint: You might need to cast the datatype of MR_tfidf_X to numpy.ndarray by using .toarray()\\n'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2b) Transform Reviews\n",
    "\n",
    "Transform the review column of MR_df into vectors using the tfidf we created above.\n",
    "\n",
    "Save the transformed data into a variable called MR_tfidf_X\n",
    "\n",
    "Hint: You might need to cast the datatype of MR_tfidf_X to numpy.ndarray by using .toarray()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "942e7fe5-3e32-4665-8681-e1e97e2619f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MR_tfidf_X = tfidf.fit_transform(MR_df['review']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "57740c76-f4e5-49ff-b1b9-90836afbb4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(MR_tfidf_X, np.ndarray)\n",
    "\n",
    "assert \"skills\" in set(tfidf.stop_words_)\n",
    "assert \"risky\" in set(tfidf.stop_words_)\n",
    "assert \"adopts\" in set(tfidf.stop_words_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f6913ef2-4f68-450d-b4f0-76ea32ca31d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n2c)\\n\\nSplit the MR_tfidf_X and MR_y into training set and test set.\\n\\nName these variables as:\\n\\nMR_train_tfidf_X and MR_train_tfidf_y for the training set\\nMR_test_tfidf_X and MR_test_tfidf_y for the test set\\nWe will use the same 80/20 split as in part 1. You can use the same num_training variable from part 1 to split up the data.\\n'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2c)\n",
    "\n",
    "Split the MR_tfidf_X and MR_y into training set and test set.\n",
    "\n",
    "Name these variables as:\n",
    "\n",
    "MR_train_tfidf_X and MR_train_tfidf_y for the training set\n",
    "MR_test_tfidf_X and MR_test_tfidf_y for the test set\n",
    "We will use the same 80/20 split as in part 1. You can use the same num_training variable from part 1 to split up the data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1c3c5f04-b1f4-41a1-bedf-4d37e4ac791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MR_train_tfidf_X = MR_tfidf_X[:num_training]\n",
    "MR_train_tfidf_y = MR_y[:num_training]\n",
    "MR_test_tfidf_X = MR_tfidf_X[num_training:]\n",
    "MR_test_tfidf_y = MR_y[num_training:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0a675837-1865-4eca-b68c-ed51e87ba86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert MR_train_tfidf_X[0].tolist() == MR_tfidf_X[0].tolist()\n",
    "assert MR_train_tfidf_X.shape == (4000, 2000)\n",
    "assert MR_test_tfidf_X.shape == (1000, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a2b25b43-100a-4a27-9628-39995dbfca9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n2d) Training\\n\\nTrain an SVM classifier on the samples MR_train_tfidf_X and the labels MR_train_tfidf_y.\\n\\nYou need to call the function train_SVM you created in part 1. Name the returned object as MR_tfidf_clf.\\n\\nNote that this may take many seconds, up to a few minutes, to run.\\n'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2d) Training\n",
    "\n",
    "Train an SVM classifier on the samples MR_train_tfidf_X and the labels MR_train_tfidf_y.\n",
    "\n",
    "You need to call the function train_SVM you created in part 1. Name the returned object as MR_tfidf_clf.\n",
    "\n",
    "Note that this may take many seconds, up to a few minutes, to run.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e9fccb7e-dfb0-426e-8267-148e4f6a72c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MR_tfidf_clf = train_SVM(MR_train_tfidf_X, MR_train_tfidf_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cc369e9c-69c8-4c5b-b3cf-3b164dd32bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(MR_clf, SVC)\n",
    "assert hasattr(MR_tfidf_clf, \"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c0be85d4-ba22-4620-a347-b8df4b3eb9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n2e) Prediction\\n\\nPredict the labels for both the training and test samples (the ‘X’ data). You will need to use MR_tfidf_clf.predict(...)\\n\\nName the predicted labels on training samples as MR_pred_train_tfidf_y. \\nName the predicted labels on testing samples as MR_pred_test_tfidf_y\\n'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2e) Prediction\n",
    "\n",
    "Predict the labels for both the training and test samples (the ‘X’ data). You will need to use MR_tfidf_clf.predict(...)\n",
    "\n",
    "Name the predicted labels on training samples as MR_pred_train_tfidf_y. \n",
    "Name the predicted labels on testing samples as MR_pred_test_tfidf_y\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8ad9e756-e69a-412e-9a3c-fa83afad9e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MR_pred_train_tfidf_y = MR_tfidf_clf.predict(MR_train_tfidf_X)\n",
    "MR_pred_test_tfidf_y = MR_tfidf_clf.predict(MR_test_tfidf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "df9ed57f-22c0-407f-83ad-5ab5618f45e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.88      0.87      2008\n",
      "         1.0       0.87      0.85      0.86      1992\n",
      "\n",
      "    accuracy                           0.86      4000\n",
      "   macro avg       0.87      0.86      0.86      4000\n",
      "weighted avg       0.87      0.86      0.86      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Again, we use classification_report to check the performance on the training set.'''\n",
    "\n",
    "# Your classifier should be able to reach above 85% accuracy.\n",
    "print(classification_report(MR_train_tfidf_y, MR_pred_train_tfidf_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d0fef03c-65c7-4d71-a88a-8687b9eb9aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.71      0.72       482\n",
      "         1.0       0.74      0.74      0.74       518\n",
      "\n",
      "    accuracy                           0.73      1000\n",
      "   macro avg       0.73      0.73      0.73      1000\n",
      "weighted avg       0.73      0.73      0.73      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' Again, check performance on the test set:'''\n",
    "\n",
    "# Your classifier should be able to reach around 70% accuracy.\n",
    "print(classification_report(MR_test_tfidf_y, MR_pred_test_tfidf_y))\n",
    "\n",
    "precision, recall, _, _ = precision_recall_fscore_support(MR_train_tfidf_y, MR_pred_train_tfidf_y)\n",
    "assert np.isclose(precision[0], 0.86, 0.02)\n",
    "assert np.isclose(precision[1], 0.87, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a369742a-35e4-4023-920e-f4d31068b62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWritten Answer Question\\n\\nHow does the performance of the TF-IDF classifier compare to the classifier used in part 1?\\n'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Written Answer Question\n",
    "\n",
    "How does the performance of the TF-IDF classifier compare to the classifier used in part 1?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "92bd61ef-0c0f-4c87-92bc-e9cb8111ec69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTF-IDF classifier is not as precise as the classifier used in part 1.\\n'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "TF-IDF classifier is not as precise as the classifier used in part 1.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7ed4cac3-6292-40a1-9f00-1b11d57faa30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPart 3: Sentiment Analysis on Customer Review with TF-IDF (2 points)\\nIn this part, we will use TF-IDF to analyse the sentiment of some Customer Review (CR) data.\\n\\nThe CR data contains around 3771 reviews, and they were all collected from the Amazon website. \\nThe reviews are annotated by humans as either positive reviews or negative reviews. \\nIn this dataset, the 2 classes are not balanced, as there are twice as many positive reviews as negative reviews.\\n\\nFor more information on this dataset, you can visit https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\\n\\nIn this part, we have already split the data into a training set and a test set, \\nin which the training set has labels for the reviews, but the test set doesn’t.\\n\\nThe goal is to train an SVM classifier on the training set, and then predict pos/neg for each review in the test set.\\n\\nTo do so, we will:\\n\\nUse the TF-IDF feature engineering method to encode the raw text data into vectors\\nTrain an SVM classifier on the training set\\nPredict labels for the reviews in the test set\\nThe performance of your trained classifier on the test set will be checked by a hidden test.\\n\\n3a) Loading the data\\n\\nCustomer review task has 2 files\\n\\n“custrev_train.tsv” contains training data with labels\\n“custrev_test.tsv” contains test data without labels which need to be predicted\\nImport raw textfile custrev_train.csv into a DataFrame called CR_train_df. Set the column names as index, label, review.\\n\\nImport raw textfile custrev_test.csv into a DataFrame called CR_test_df. Set the column names as index, review\\n\\nNote that both will need to be imported with sep and header arguments (like in 1a)\\n'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Part 3: Sentiment Analysis on Customer Review with TF-IDF (2 points)\n",
    "In this part, we will use TF-IDF to analyse the sentiment of some Customer Review (CR) data.\n",
    "\n",
    "The CR data contains around 3771 reviews, and they were all collected from the Amazon website. \n",
    "The reviews are annotated by humans as either positive reviews or negative reviews. \n",
    "In this dataset, the 2 classes are not balanced, as there are twice as many positive reviews as negative reviews.\n",
    "\n",
    "For more information on this dataset, you can visit https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\n",
    "\n",
    "In this part, we have already split the data into a training set and a test set, \n",
    "in which the training set has labels for the reviews, but the test set doesn’t.\n",
    "\n",
    "The goal is to train an SVM classifier on the training set, and then predict pos/neg for each review in the test set.\n",
    "\n",
    "To do so, we will:\n",
    "\n",
    "Use the TF-IDF feature engineering method to encode the raw text data into vectors\n",
    "Train an SVM classifier on the training set\n",
    "Predict labels for the reviews in the test set\n",
    "The performance of your trained classifier on the test set will be checked by a hidden test.\n",
    "\n",
    "3a) Loading the data\n",
    "\n",
    "Customer review task has 2 files\n",
    "\n",
    "“custrev_train.tsv” contains training data with labels\n",
    "“custrev_test.tsv” contains test data without labels which need to be predicted\n",
    "Import raw textfile custrev_train.csv into a DataFrame called CR_train_df. Set the column names as index, label, review.\n",
    "\n",
    "Import raw textfile custrev_test.csv into a DataFrame called CR_test_df. Set the column names as index, review\n",
    "\n",
    "Note that both will need to be imported with sep and header arguments (like in 1a)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "54aa9df0-5a41-4d89-bb9d-56a886ac15a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_train_file = 'custrev_train.tsv'\n",
    "CR_test_file = 'custrev_test.tsv'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "CR_train_df = pd.read_csv(CR_train_file, names=['index', 'label', 'review'], header=None, sep='\\t')\n",
    "CR_test_df = pd.read_csv(CR_test_file, names=['index', 'review'], header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cf7f48cd-8530-4134-8725-474ac5704c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(CR_train_df, pd.DataFrame)\n",
    "assert isinstance(CR_test_df, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "13765f05-893e-437a-a0c7-404e7fc66346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3b) Concatenation\\n\\nConcatenate the 2 DataFrames from the last step into a single DataFrame, and name it CR_df.\\n'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3b) Concatenation\n",
    "\n",
    "Concatenate the 2 DataFrames from the last step into a single DataFrame, and name it CR_df.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "049d0e32-c936-46d5-8e50-f5f352f88032",
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_df = pd.concat([CR_train_df, CR_test_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "35cde5c2-0786-447e-b5d8-caac25a9c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(CR_df) == 3771"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "bb637621-6eab-4963-b368-f5c2b447a477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3c) Cleaning\\n\\nConvert all labels in CR_df[\"label\"] using the convert_label function we defined above. \\nSave these numerical labels as a new column named y in CR_df.\\n'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3c) Cleaning\n",
    "\n",
    "Convert all labels in CR_df[\"label\"] using the convert_label function we defined above. \n",
    "Save these numerical labels as a new column named y in CR_df.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f015bda6-712d-473c-8180-529a54914efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_df['y'] = CR_df['label'].apply(convert_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "17bc65b7-e8da-45cc-b2bf-2f09980ffa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(CR_df['y'], pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bfa44525-ff6b-4f5f-aaa2-5c9c937f3585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3d) Use tfidf\\n\\nTransform reviews CR_df[\"review\"] into vectors using the tfidf vectorizer we created in part 2. \\nSave the transformed data into a variable called CR_tfidf_X.\\n'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3d) Use tfidf\n",
    "\n",
    "Transform reviews CR_df[\"review\"] into vectors using the tfidf vectorizer we created in part 2. \n",
    "Save the transformed data into a variable called CR_tfidf_X.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "cbeb2052-690b-4fe3-bcbf-a00b117d9bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_tfidf_X = tfidf.fit_transform(CR_df[\"review\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a74de4cd-308d-4aef-9575-e324fb3cefbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(CR_tfidf_X, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1b1aad20-3a8c-4f0c-8e23-0605233e9cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we will collect all training samples & numerical labels from CR_tfidf_X. \n",
    "The code provided below will extract all samples with labels from the dataframe:\n",
    "'''\n",
    "# code provided to collect labels\n",
    "CR_train_X = CR_tfidf_X[~CR_df['y'].isnull()]\n",
    "CR_train_y = CR_df['y'][~CR_df['y'].isnull()]\n",
    "\n",
    "# Note: if these asserts fail, something went wrong\n",
    "#  Go back and check your code (in part 3) above this cell\n",
    "assert CR_train_X.shape == (3016, 2000)\n",
    "assert CR_train_y.shape == (3016, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "92c892e2-6c5f-4c41-b0da-013112a78402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3e) SVM\\n\\nTrain an SVM classifier on the samples CR_train_X and the labels CR_train_y:\\n\\nYou need to call the function train_SVM you created above.\\nName the returned object as CR_clf.\\nNote that this function will take many seconds / up to a few minutes to run.\\n'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3e) SVM\n",
    "\n",
    "Train an SVM classifier on the samples CR_train_X and the labels CR_train_y:\n",
    "\n",
    "You need to call the function train_SVM you created above.\n",
    "Name the returned object as CR_clf.\n",
    "Note that this function will take many seconds / up to a few minutes to run.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "04e66594-97be-43f1-8b34-ea03d132bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_clf = train_SVM(CR_train_X, CR_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b2d5593a-9c09-4ac1-89c3-c318c1529b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(CR_clf, SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "dbc25861-84f4-40d9-8294-9cf3a2220bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3f) Predict: training data\\n\\nPredict labels on the training set, and name the returned variable as CR_pred_train_y\\n'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3f) Predict: training data\n",
    "\n",
    "Predict labels on the training set, and name the returned variable as CR_pred_train_y\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a4c6ef32-dc47-48b9-90c7-be21b7a78242",
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_pred_train_y = CR_clf.predict(CR_train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a652c725-7e07-49a8-baad-76919e0c98fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.84      0.87      1097\n",
      "         1.0       0.91      0.95      0.93      1919\n",
      "\n",
      "    accuracy                           0.91      3016\n",
      "   macro avg       0.91      0.89      0.90      3016\n",
      "weighted avg       0.91      0.91      0.91      3016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier accuracy on the train data\n",
    "#   Note that your classifier should be able to reach above 90% accuracy.\n",
    "print(classification_report(CR_train_y, CR_pred_train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "950ca680-4127-4a24-b8ed-f029754046dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, _, _ = precision_recall_fscore_support(CR_train_y, CR_pred_train_y)\n",
    "assert np.isclose(precision[0], 0.90, 0.02)\n",
    "assert np.isclose(precision[1], 0.91, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6b23936a-57d7-46cd-b5ea-5925a682ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all test samples from CR_tfidf_X\n",
    "CR_test_X = CR_tfidf_X[CR_df['y'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "efa82544-0b39-4e0a-b7c1-646727ed1fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3g) Predict: test set\\n\\nPredict the labels on the test set. Name the returned variable as CR_pred_test_y\\n'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3g) Predict: test set\n",
    "\n",
    "Predict the labels on the test set. Name the returned variable as CR_pred_test_y\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6025b5c2-e4a5-407c-80e4-d180b8970c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_pred_test_y = CR_clf.predict(CR_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3d6d6160-63b4-4a2c-b423-0e186b957b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(CR_test_X, np.ndarray)\n",
    "assert isinstance(CR_pred_test_y, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "61802cde-52c6-4e97-81e3-dd280b81ddd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3h) Convert labels\\n\\nConvert the predicted numerical labels back to string labels (“pos” and “neg”).\\n\\nCreate a column called label in CR_test_df to store the converted labels.\\n'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3h) Convert labels\n",
    "\n",
    "Convert the predicted numerical labels back to string labels (“pos” and “neg”).\n",
    "\n",
    "Create a column called label in CR_test_df to store the converted labels.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "276810a9-95bf-4570-af0d-ae1d46f6dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = []\n",
    "for label in CR_pred_test_y:\n",
    "    if label == 1.0:\n",
    "        lc.append('pos')\n",
    "    elif label == 0.0:\n",
    "        lc.append('neg')\n",
    "    else:\n",
    "        lc.append(label)\n",
    "        \n",
    "CR_test_df['label'] = lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "08f395a5-f689-4661-aea3-e683af2c63bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe hidden assignments tests for the cell above will check that your model predicts the right number \\nof pos/neg reviews in the test data provided.\\n\\nWe now have a model that can predict positive or negative sentiment!\\n\\nIn the cell below, as a written answer question, briefly, in your own words, \\nwhat BoW and TF/IDF word representations are, and how they differ. \\nAlso, think about and write a quick example \\nof when and why it might be useful to automatically analyze the sentiment of text data. \\n[This whole answer can/should be a couple of sentences].\\n\\nAfter you answer this question, you are done!\\n'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The hidden assignments tests for the cell above will check that your model predicts the right number \n",
    "of pos/neg reviews in the test data provided.\n",
    "\n",
    "We now have a model that can predict positive or negative sentiment!\n",
    "\n",
    "In the cell below, as a written answer question, briefly, in your own words, \n",
    "what BoW and TF/IDF word representations are, and how they differ. \n",
    "Also, think about and write a quick example \n",
    "of when and why it might be useful to automatically analyze the sentiment of text data. \n",
    "[This whole answer can/should be a couple of sentences].\n",
    "\n",
    "After you answer this question, you are done!\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5736d1fa-39f0-4007-99de-837139c14aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThe BoW model interprets that the words that appear more often in a dataset are more important, \\nwhile the TF/IDF model does the opposit.\\nI think that automatically analyze the sentiment of text data is very important when analyzing\\ncustomers feedback, survey's, and basically any data with open responses.\\n\""
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The BoW model interprets that the words that appear more often in a dataset are more important, \n",
    "while the TF/IDF model does the opposit.\n",
    "I think that automatically analyze the sentiment of text data is very important when analyzing\n",
    "customers feedback, survey's, and basically any data with open responses.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef49c864-1859-4e05-8b88-076e91ba3b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
